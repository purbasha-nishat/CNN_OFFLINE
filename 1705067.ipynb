{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score, f1_score\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseModel:\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution: There will be four (hyper)parameters:\n",
    "1. Number of output channels\n",
    "2. Filter dimension\n",
    "3. Stride\n",
    "4. Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Links\n",
    "#### Backward\n",
    "1. [conv backward dx](https://medium.com/@mayank.utexas/backpropagation-for-convolution-with-strides-8137e4fc2710)\n",
    "2. [conv backward dw, db](https://medium.com/@mayank.utexas/backpropagation-for-convolution-with-strides-fb2f2efc4faa)\n",
    "3. [conv implement](https://github.com/slvrfn/vectorized_convolution/blob/master/convolution.py?fbclid=IwAR1SFj7zg2banabtjIWb9Rjrww1rjuGX4CZ7u8UHGIH3BJHnaSkMnhx2jdU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionLayer(baseModel):\n",
    "    def __init__(self, output_channel, kernel_size, stride, padding):\n",
    "        self.output_channel = output_channel\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.x = None\n",
    "        self.window_arr = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x # batch_size, channel, height, width\n",
    "        batch_size, channel, height, width = x.shape\n",
    "        output_height = (height - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
    "        output_width = (width - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
    "        self.output = np.zeros((batch_size, self.output_channel,  output_height, output_width))\n",
    "        if self.weights is None:\n",
    "            # init weight with Xavier method\n",
    "            self.weights = np.random.randn(self.output_channel, channel, self.kernel_size, self.kernel_size) * np.sqrt(2 / (channel * self.kernel_size * self.kernel_size))\n",
    "            self.bias = np.random.randn(self.output_channel)\n",
    "        \n",
    "        window_arr = np.lib.stride_tricks.as_strided(x, \n",
    "            shape=(batch_size, channel, output_height, output_width, self.kernel_size, self.kernel_size), \n",
    "            strides=(x.strides[0], x.strides[1], x.strides[2]*self.stride, x.strides[3]*self.stride, x.strides[2], x.strides[3]))\n",
    "\n",
    "        self.window_arr = window_arr\n",
    "        self.output = np.einsum('bihwkl,oikl->bohw', window_arr, self.weights) + self.bias[None, :, None, None]\n",
    "        return self.output\n",
    "\n",
    "\n",
    "    # backward prop vectorized\n",
    "    def backward(self, output, learning_rate):\n",
    "        \n",
    "        x = self.x\n",
    "        window_arr = self.window_arr\n",
    "        dilate = self.stride - 1\n",
    "        padding = self.kernel_size - 1 if self.padding == 0 else self.padding\n",
    "        working_input = output\n",
    "\n",
    "        # dilate the input if necessary\n",
    "        if dilate != 0:\n",
    "            working_input = np.insert(working_input, range(1, output.shape[2]), 0, axis=2)\n",
    "            working_input = np.insert(working_input, range(1, output.shape[3]), 0, axis=3)\n",
    "\n",
    "        # pad the input if necessary\n",
    "        if self.padding != 0:\n",
    "            working_input = np.pad(working_input, pad_width=((0,), (0,), (padding,), (padding,)), mode='constant', constant_values=(0.,))\n",
    "\n",
    "        in_batch, in_channel, out_height, out_width = x.shape\n",
    "        out_batch, out_channel, _, _ = output.shape\n",
    "        batch_str, channel_str, kern_h_str, kern_w_str = working_input.strides\n",
    "        stride = 1\n",
    "\n",
    "        window_arr_out = np.lib.stride_tricks.as_strided(\n",
    "        working_input,\n",
    "        (out_batch, out_channel, out_height, out_width, self.kernel_size, self.kernel_size),\n",
    "        (batch_str, channel_str, stride*kern_h_str, stride*kern_w_str, kern_h_str, kern_w_str))\n",
    "\n",
    "        rotated_kernel = np.rot90(self.weights, 2, axes=(2, 3))\n",
    "\n",
    "        db = np.sum(output, axis=(0, 2, 3))\n",
    "        dw = np.einsum('bihwkl,bohw->oikl', window_arr, output)\n",
    "        dx = np.einsum('bohwkl,oikl->bihw', window_arr_out, rotated_kernel)\n",
    "\n",
    "        self.weights -= learning_rate * dw\n",
    "        self.bias -= learning_rate * db\n",
    "\n",
    "        return dx\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [[[[-12.5 -11.5 -10.5  -9.5  -8.5]\n",
      "   [ -7.5  -6.5  -5.5  -4.5  -3.5]\n",
      "   [ -2.5  -1.5  -0.5   0.5   1.5]\n",
      "   [  2.5   3.5   4.5   5.5   6.5]\n",
      "   [  7.5   8.5   9.5  10.5  11.5]]]]\n",
      "\n",
      "<__main__.ConvolutionLayer object at 0x7f799bfbcf70>\n",
      "(1, 1, 3, 3)\n",
      "output--------\n",
      "[[[[ 15.67624339  13.37258777  11.06893214]\n",
      "   [  4.15796527   1.85430965  -0.44934598]\n",
      "   [ -7.36031285  -9.66396847 -11.9676241 ]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 1*1*5*5\n",
    "input_arr = np.arange(-count/2, count/2).reshape(1, 1, 5, 5)\n",
    "print(f'input: {input_arr}\\n')\n",
    "conv_layer = ConvolutionLayer(1, 3, 1, 0)\n",
    "print(conv_layer)\n",
    "output = conv_layer.forward(input_arr)\n",
    "print(output.shape)\n",
    "print(f'output--------\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLULayer(baseModel):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        self.output = output\n",
    "        return self.output * (self.x > 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 3, 3)\n",
      "output--------\n",
      "[[[[15.67624339 13.37258777 11.06893214]\n",
      "   [ 4.15796527  1.85430965  0.        ]\n",
      "   [ 0.          0.          0.        ]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "relu_layer = ReLULayer()\n",
    "output = relu_layer.forward(output)\n",
    "print(output.shape)\n",
    "print(f'output--------\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaxPooling: There will be two parameters:\n",
    "1. Filter dimension\n",
    "2. Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Links\n",
    "#### Backward\n",
    "1. [Maxpool Backward](https://stackoverflow.com/questions/61954727/max-pooling-backpropagation-using-numpy?fbclid=IwAR2PkO13F1_Jy99n5fysZD_dvHvqYQTPqno8Z-CLVt2-P664zjU1omJxMsQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolingLayer(baseModel):\n",
    "    def __init__(self, pool_size, stride):\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        batch_size, channel, height, width = x.shape\n",
    "        output_height = (height - self.pool_size) // self.stride + 1\n",
    "        output_width = (width - self.pool_size) // self.stride + 1\n",
    "        self.output = np.zeros((batch_size, channel, output_height, output_width))\n",
    "        \n",
    "        # maxpooling without loop\n",
    "        new_arr = np.lib.stride_tricks.as_strided(x, \n",
    "            shape=(batch_size, channel, output_height, output_width, self.pool_size, self.pool_size), \n",
    "            strides=(x.strides[0], x.strides[1], x.strides[2] * self.stride, x.strides[3] * self.stride, x.strides[2], x.strides[3]))\n",
    "        self.output = np.max(new_arr, axis=(4, 5))\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        x = self.x\n",
    "        batch_size, channel, height, width = x.shape\n",
    "        out_batch, out_channel, out_height, out_width = output.shape\n",
    "\n",
    "        dx = np.zeros(shape=x.shape)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            for j in range(channel):\n",
    "                for k in range(out_height):\n",
    "                    for l in range(out_width):\n",
    "                        # get the index in the region i,j where the value is the maximum\n",
    "                        i_t, j_t = np.where(np.max(x[i, j, k * self.stride : k * self.stride + self.pool_size, l * self.stride : l * self.stride + self.pool_size]) == x[i, j, k * self.stride : k * self.stride + self.pool_size, l * self.stride : l * self.stride + self.pool_size])\n",
    "                        i_t, j_t = i_t[0], j_t[0]\n",
    "                        # print(i_t, j_t)\n",
    "                        # only the position of the maximum element in the region i,j gets the incoming gradient, the other gradients are zero\n",
    "                        dx[i, j, k * self.stride : k * self.stride + self.pool_size, l * self.stride : l * self.stride + self.pool_size][i_t, j_t] = output[i, j, k, l]\n",
    "        return dx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 2, 2)\n",
      "output--------\n",
      "[[[[15.67624339 13.37258777]\n",
      "   [ 4.15796527  1.85430965]]]]\n",
      "\n",
      "(1, 1, 3, 3)\n",
      "output--------\n",
      "[[[[15.67624339 13.37258777  0.        ]\n",
      "   [ 4.15796527  1.85430965  0.        ]\n",
      "   [ 0.          0.          0.        ]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxpool_layer = MaxPoolingLayer(2, 1)   \n",
    "output = maxpool_layer.forward(output)\n",
    "\n",
    "print(output.shape)\n",
    "print(f'output--------\\n{output}\\n')\n",
    "\n",
    "output_rev = maxpool_layer.backward(output, 0.1)\n",
    "print(output_rev.shape)\n",
    "print(f'output--------\\n{output_rev}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatteningLayer(baseModel):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        batch_size, channel, height, width = x.shape\n",
    "        self.output = x.reshape((batch_size, channel * height * width))\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        self.output = output\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        dx = self.output.reshape(self.x.shape)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "output--------\n",
      "[[15.67624339 13.37258777  4.15796527  1.85430965]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flat_layer = FlatteningLayer()\n",
    "output = flat_layer.forward(output)\n",
    "print(output.shape)\n",
    "print(f'output--------\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-connected layer: a dense layer. There will be one paramete:\n",
    "1. Output dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer(baseModel):\n",
    "    def __init__(self, output_channel):\n",
    "        self.output_channel = output_channel\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        if self.weights is None:\n",
    "            self.weights = np.random.randn(self.x.shape[1], self.output_channel) * np.sqrt(2 / self.x.shape[1])\n",
    "            self.bias = np.random.randn(self.output_channel)\n",
    "            \n",
    "        self.output = np.dot(self.x, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        self.output = output\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        dx = np.dot(self.output, self.weights.T)\n",
    "        dw = np.dot(self.x.T, self.output)\n",
    "        db = np.sum(self.output, axis=0)\n",
    "\n",
    "        self.weights -= self.learning_rate * dw \n",
    "        self.bias -= self.learning_rate * db\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n",
      "output--------\n",
      "[[-12.27200316   2.73852758 -17.56907209  32.94222365  -0.55384001\n",
      "   -9.99676855  -3.3493249    3.81405259 -12.45593105  -7.59489822]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fullConn_layer = FullyConnectedLayer(10)\n",
    "output = fullConn_layer.forward(output)\n",
    "print(output.shape)\n",
    "print(f'output--------\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax: it will convert final layer projections to normalized probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLayer(baseModel):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        # normalize input\n",
    "        x -= np.max(x, axis=1, keepdims=True)\n",
    "        self.output = np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n",
      "output--------\n",
      "[[2.31052565e-20 7.63310899e-14 1.15670599e-22 1.00000000e+00\n",
      "  2.83690235e-15 2.24818802e-19 1.73292881e-16 2.23767001e-13\n",
      "  1.92234761e-20 2.48285673e-18]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax_layer = SoftmaxLayer()\n",
    "output = softmax_layer.forward(output)\n",
    "print(output.shape)\n",
    "print(f'output--------\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    model = []\n",
    "    \n",
    "    model.append(ConvolutionLayer(6, 5, 1, 0))\n",
    "    model.append(ReLULayer())\n",
    "    model.append(MaxPoolingLayer(2, 2))\n",
    "    model.append(ConvolutionLayer(16, 5, 1, 0))\n",
    "    model.append(ReLULayer())\n",
    "    model.append(MaxPoolingLayer(2, 2))\n",
    "    model.append(FlatteningLayer())\n",
    "    model.append(FullyConnectedLayer(120))\n",
    "    model.append(ReLULayer())\n",
    "    model.append(FullyConnectedLayer(84))\n",
    "    model.append(ReLULayer())\n",
    "    model.append(FullyConnectedLayer(10))\n",
    "    model.append(SoftmaxLayer())\n",
    "    print('model created: ', model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get images\n",
    "def getImages(path):\n",
    "    images = []\n",
    "    count = 0\n",
    "    path_split = path.split('.')\n",
    "    new_path = path_split[0]\n",
    "    df = pd.read_csv(path)\n",
    "    files = df['filename']\n",
    "    for file in files:\n",
    "        if count == 500:\n",
    "            break\n",
    "        img = cv2.imread(os.path.join(new_path, file))\n",
    "        img = cv2.resize(img, (28, 28))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = (255-img.transpose(2, 0, 1))/255\n",
    "        images.append(img)\n",
    "        count += 1\n",
    "\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "def getLabels(path):\n",
    "    labels = []\n",
    "    # using panda\n",
    "    count = 500\n",
    "    df = pd.read_csv(path)\n",
    "    labels = df['digit'][:count]\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "def train(model, X_train, X_test, Y_train, Y_test, learning_rate, epochs):\n",
    "    batch_size = 32\n",
    "    for epoch in range(epochs):\n",
    "        print(f'epoch: {epoch+1}/{epochs}')\n",
    "        num_batches = X_train.shape[0] // batch_size\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        for i in tqdm(range(num_batches)):\n",
    "            # forward\n",
    "            x_batch = X_train[i*batch_size: (i+1)*batch_size]\n",
    "            y_output = Y_train[i*batch_size: (i+1)*batch_size]\n",
    "\n",
    "            x_output = x_batch\n",
    "            for layer in model:\n",
    "                x_output = layer.forward(x_output)\n",
    "            \n",
    "            #loss\n",
    "            loss += log_loss(y_output, x_output)\n",
    "            accuracy += accuracy_score(np.argmax(y_output, axis=1), np.argmax(x_output, axis=1))\n",
    "\n",
    "            dL = np.copy(x_output)\n",
    "            dL -= y_output\n",
    "            dL /= batch_size\n",
    "            # backward\n",
    "            for layer in reversed(model):\n",
    "                dL = layer.backward(dL, learning_rate)\n",
    "        \n",
    "        # test\n",
    "        val_loss = 0\n",
    "        \n",
    "        x_out = X_test\n",
    "        for layer in model:\n",
    "            x_out = layer.forward(x_out)\n",
    "\n",
    "        # print(f'loss: {loss/num_batches}, val_loss: {val_loss}')\n",
    "        val_loss = log_loss(Y_test, x_out)\n",
    "        val_accuracy = accuracy_score(np.argmax(Y_test, axis=1), np.argmax(x_out, axis=1))\n",
    "        val_F1 = f1_score(np.argmax(Y_test, axis=1), np.argmax(x_out, axis=1), average='macro')\n",
    "        print(f'loss: {loss/num_batches}, val_loss: {val_loss}')\n",
    "        print(f'accuracy: {accuracy/num_batches}, val_accuracy: {val_accuracy}')\n",
    "        print(f'val_F1: {val_F1}')\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3, 28, 28)\n",
      "(500, 10)\n",
      "[0 0 0 1 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = getImages('data/training-a.csv')\n",
    "labels = getLabels('data/training-a.csv')\n",
    "# # images.append(image)\n",
    "# # labels.append(label)\n",
    "# image += getImages('data/training-b')\n",
    "# label += getLabels('data/training-b.csv')\n",
    "# # images.append(image)\n",
    "# # labels.append(label)\n",
    "\n",
    "\n",
    "# one hot encode\n",
    "labels = np.eye(10)[labels].astype(int)\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "# view an image\n",
    "plt.imshow(images[1].transpose(1, 2, 0))\n",
    "print(labels[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model created:  [<__main__.ConvolutionLayer object at 0x7f7995316700>, <__main__.ReLULayer object at 0x7f79953163a0>, <__main__.MaxPoolingLayer object at 0x7f7990d525b0>, <__main__.ConvolutionLayer object at 0x7f7990d6ba30>, <__main__.ReLULayer object at 0x7f7990d6b850>, <__main__.MaxPoolingLayer object at 0x7f7990d6b040>, <__main__.FlatteningLayer object at 0x7f7990d6b4c0>, <__main__.FullyConnectedLayer object at 0x7f7990d6baf0>, <__main__.ReLULayer object at 0x7f7990d6bc40>, <__main__.FullyConnectedLayer object at 0x7f7990d6ba00>, <__main__.ReLULayer object at 0x7f7990d6b520>, <__main__.FullyConnectedLayer object at 0x7f7990d6b790>, <__main__.SoftmaxLayer object at 0x7f7990d6b310>]\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 3, 28, 28)\n",
      "(100, 3, 28, 28)\n",
      "(400, 10)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.9672525010166253, val_loss: 2.836152274708947\n",
      "accuracy: 0.1171875, val_accuracy: 0.09\n",
      "val_F1: 0.025354609929078016\n",
      "epoch: 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.5497076551840765, val_loss: 2.485041607006074\n",
      "accuracy: 0.08072916666666667, val_accuracy: 0.07\n",
      "val_F1: 0.02365967365967366\n",
      "epoch: 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:08<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.3600535344456053, val_loss: 2.4166346096923963\n",
      "accuracy: 0.08333333333333333, val_accuracy: 0.09\n",
      "val_F1: 0.025757575757575757\n",
      "epoch: 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:08<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.315715970460946, val_loss: 2.377932483018028\n",
      "accuracy: 0.09635416666666667, val_accuracy: 0.07\n",
      "val_F1: 0.03135610766045548\n",
      "epoch: 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:08<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.30328877291504, val_loss: 2.366345440452259\n",
      "accuracy: 0.1015625, val_accuracy: 0.08\n",
      "val_F1: 0.05205828779599271\n",
      "epoch: 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:08<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.299205538456547, val_loss: 2.360036696591461\n",
      "accuracy: 0.1171875, val_accuracy: 0.06\n",
      "val_F1: 0.04148148148148149\n",
      "epoch: 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:08<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.297784357305663, val_loss: 2.347151714402612\n",
      "accuracy: 0.13541666666666666, val_accuracy: 0.11\n",
      "val_F1: 0.07300660865013413\n",
      "epoch: 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:08<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2938113707346983, val_loss: 2.3532842449378752\n",
      "accuracy: 0.1328125, val_accuracy: 0.1\n",
      "val_F1: 0.05861329147043433\n",
      "epoch: 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:08<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.292778470162734, val_loss: 2.3493923219130135\n",
      "accuracy: 0.1328125, val_accuracy: 0.11\n",
      "val_F1: 0.07020358868184956\n",
      "epoch: 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.288443596244044, val_loss: 2.3452515286647486\n",
      "accuracy: 0.1328125, val_accuracy: 0.12\n",
      "val_F1: 0.0808832676757205\n",
      "epoch: 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.290206150157011, val_loss: 2.3432909909229944\n",
      "accuracy: 0.13020833333333334, val_accuracy: 0.1\n",
      "val_F1: 0.07177482713876891\n",
      "epoch: 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.290283984717533, val_loss: 2.3435387957801828\n",
      "accuracy: 0.1484375, val_accuracy: 0.12\n",
      "val_F1: 0.0772530680805357\n",
      "epoch: 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2876305864654403, val_loss: 2.346176133401419\n",
      "accuracy: 0.13020833333333334, val_accuracy: 0.1\n",
      "val_F1: 0.04781791685841386\n",
      "epoch: 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.286491294949026, val_loss: 2.3418292200064696\n",
      "accuracy: 0.1484375, val_accuracy: 0.08\n",
      "val_F1: 0.037609427609427606\n",
      "epoch: 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:10<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2844957086490827, val_loss: 2.3460248020543064\n",
      "accuracy: 0.13541666666666666, val_accuracy: 0.1\n",
      "val_F1: 0.049107812265707\n",
      "epoch: 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2851876593371827, val_loss: 2.346004362423859\n",
      "accuracy: 0.13541666666666666, val_accuracy: 0.1\n",
      "val_F1: 0.04759869759869761\n",
      "epoch: 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.283075572862576, val_loss: 2.3367358239152423\n",
      "accuracy: 0.12760416666666666, val_accuracy: 0.11\n",
      "val_F1: 0.05868679675259934\n",
      "epoch: 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:10<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.283159343977389, val_loss: 2.3370858938172225\n",
      "accuracy: 0.140625, val_accuracy: 0.11\n",
      "val_F1: 0.07208791208791207\n",
      "epoch: 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2811325427741544, val_loss: 2.331096529006711\n",
      "accuracy: 0.1484375, val_accuracy: 0.15\n",
      "val_F1: 0.09123475596495453\n",
      "epoch: 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2805432991498216, val_loss: 2.3246566194434326\n",
      "accuracy: 0.140625, val_accuracy: 0.14\n",
      "val_F1: 0.10054323725055432\n",
      "epoch: 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2779542485623643, val_loss: 2.3300762465725207\n",
      "accuracy: 0.140625, val_accuracy: 0.11\n",
      "val_F1: 0.07028923897641076\n",
      "epoch: 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2749339901083676, val_loss: 2.3257304396163705\n",
      "accuracy: 0.13541666666666666, val_accuracy: 0.11\n",
      "val_F1: 0.07513731479248721\n",
      "epoch: 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2728803104985924, val_loss: 2.324567504269011\n",
      "accuracy: 0.14583333333333334, val_accuracy: 0.13\n",
      "val_F1: 0.08046729840208101\n",
      "epoch: 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2732935777869065, val_loss: 2.322101939602181\n",
      "accuracy: 0.1484375, val_accuracy: 0.12\n",
      "val_F1: 0.06736263736263737\n",
      "epoch: 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.272601473696828, val_loss: 2.3226071251148293\n",
      "accuracy: 0.14583333333333334, val_accuracy: 0.12\n",
      "val_F1: 0.06539682539682541\n",
      "epoch: 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2709748930256075, val_loss: 2.321856955780622\n",
      "accuracy: 0.1484375, val_accuracy: 0.13\n",
      "val_F1: 0.05753968253968254\n",
      "epoch: 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2689988581034517, val_loss: 2.319619126473372\n",
      "accuracy: 0.14322916666666666, val_accuracy: 0.12\n",
      "val_F1: 0.057381573665194696\n",
      "epoch: 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.268180970752074, val_loss: 2.3185576559891863\n",
      "accuracy: 0.15625, val_accuracy: 0.12\n",
      "val_F1: 0.06432535885167465\n",
      "epoch: 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2672675986396738, val_loss: 2.3168751696846828\n",
      "accuracy: 0.14322916666666666, val_accuracy: 0.13\n",
      "val_F1: 0.05980392156862745\n",
      "epoch: 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2660713421776797, val_loss: 2.3158952089432536\n",
      "accuracy: 0.13541666666666666, val_accuracy: 0.12\n",
      "val_F1: 0.057551939924906134\n"
     ]
    }
   ],
   "source": [
    "train(model, X_train, X_test, Y_train, Y_test, 0.001, 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
