{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score, f1_score\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseModel:\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution: There will be four (hyper)parameters:\n",
    "1. Number of output channels\n",
    "2. Filter dimension\n",
    "3. Stride\n",
    "4. Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Links\n",
    "#### Backward\n",
    "1. [conv backward dx](https://medium.com/@mayank.utexas/backpropagation-for-convolution-with-strides-8137e4fc2710)\n",
    "2. [conv backward dw, db](https://medium.com/@mayank.utexas/backpropagation-for-convolution-with-strides-fb2f2efc4faa)\n",
    "3. [conv implement](https://github.com/slvrfn/vectorized_convolution/blob/master/convolution.py?fbclid=IwAR1SFj7zg2banabtjIWb9Rjrww1rjuGX4CZ7u8UHGIH3BJHnaSkMnhx2jdU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionLayer(baseModel):\n",
    "    def __init__(self, output_channel, kernel_size, stride, padding):\n",
    "        self.output_channel = output_channel\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.x = None\n",
    "        self.window_arr = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x # batch_size, channel, height, width\n",
    "        batch_size, channel, height, width = x.shape\n",
    "        output_height = (height - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
    "        output_width = (width - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
    "        self.output = np.zeros((batch_size, self.output_channel,  output_height, output_width))\n",
    "        if self.weights is None:\n",
    "            # init weight with Xavier method\n",
    "            self.weights = np.random.randn(self.output_channel, channel, self.kernel_size, self.kernel_size) * np.sqrt(2 / (channel * self.kernel_size * self.kernel_size))\n",
    "            self.bias = np.zeros(self.output_channel)\n",
    "        \n",
    "        window_arr = np.lib.stride_tricks.as_strided(x, \n",
    "            shape=(batch_size, channel, output_height, output_width, self.kernel_size, self.kernel_size), \n",
    "            strides=(x.strides[0], x.strides[1], x.strides[2]*self.stride, x.strides[3]*self.stride, x.strides[2], x.strides[3]))\n",
    "\n",
    "        self.window_arr = window_arr\n",
    "        self.output = np.einsum('bihwkl,oikl->bohw', window_arr, self.weights) + self.bias[None, :, None, None]\n",
    "        return self.output\n",
    "\n",
    "\n",
    "    # backward prop vectorized\n",
    "    def backward(self, output, learning_rate):\n",
    "        \n",
    "        x = self.x\n",
    "        window_arr = self.window_arr\n",
    "        dilate = self.stride - 1\n",
    "        padding = self.kernel_size - 1 if self.padding == 0 else self.padding\n",
    "        working_input = output\n",
    "\n",
    "        # dilate the input if necessary\n",
    "        if dilate != 0:\n",
    "            working_input = np.insert(working_input, range(1, output.shape[2]), 0, axis=2)\n",
    "            working_input = np.insert(working_input, range(1, output.shape[3]), 0, axis=3)\n",
    "\n",
    "        # pad the input if necessary\n",
    "        if padding != 0:\n",
    "            working_input = np.pad(working_input, ((0,0), (0,0), (padding, padding), (padding, padding)), 'constant')\n",
    "\n",
    "        in_batch, in_channel, out_height, out_width = x.shape\n",
    "        out_batch, out_channel, _, _ = output.shape\n",
    "        batch_str, channel_str, kern_h_str, kern_w_str = working_input.strides\n",
    "        stride = 1\n",
    "\n",
    "        window_arr_out = np.lib.stride_tricks.as_strided(\n",
    "        working_input,\n",
    "        (out_batch, out_channel, out_height, out_width, self.kernel_size, self.kernel_size),\n",
    "        (batch_str, channel_str, stride*kern_h_str, stride*kern_w_str, kern_h_str, kern_w_str))\n",
    "\n",
    "        rotated_kernel = np.rot90(self.weights, 2, axes=(2, 3))\n",
    "\n",
    "        dx = np.einsum('bohwkl,oikl->bihw', window_arr_out, rotated_kernel)\n",
    "        db = np.sum(output, axis=(0, 2, 3))\n",
    "        dw = np.einsum('bihwkl,bohw->oikl', window_arr, output)\n",
    "        \n",
    "        self.weights -= learning_rate * dw\n",
    "        self.bias -= learning_rate * db\n",
    "\n",
    "        return dx\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [[[[-12.5 -11.5 -10.5  -9.5  -8.5]\n",
      "   [ -7.5  -6.5  -5.5  -4.5  -3.5]\n",
      "   [ -2.5  -1.5  -0.5   0.5   1.5]\n",
      "   [  2.5   3.5   4.5   5.5   6.5]\n",
      "   [  7.5   8.5   9.5  10.5  11.5]]]]\n",
      "\n",
      "<__main__.ConvolutionLayer object at 0x7fe9e46df190>\n",
      "(1, 1, 3, 3)\n",
      "output--------\n",
      "[[[[-5.39317786 -5.00821337 -4.62324888]\n",
      "   [-3.46835542 -3.08339093 -2.69842644]\n",
      "   [-1.54353298 -1.15856849 -0.773604  ]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 1*1*5*5\n",
    "input_arr = np.arange(-count/2, count/2).reshape(1, 1, 5, 5)\n",
    "print(f'input: {input_arr}\\n')\n",
    "conv_layer = ConvolutionLayer(1, 3, 1, 0)\n",
    "print(conv_layer)\n",
    "output = conv_layer.forward(input_arr)\n",
    "print(output.shape)\n",
    "print(f'output--------\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLULayer(baseModel):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        self.output = output\n",
    "        return self.output * (self.x > 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 3, 3)\n",
      "output--------\n",
      "[[[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "relu_layer = ReLULayer()\n",
    "output = relu_layer.forward(output)\n",
    "print(output.shape)\n",
    "print(f'output--------\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaxPooling: There will be two parameters:\n",
    "1. Filter dimension\n",
    "2. Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Links\n",
    "#### Backward\n",
    "1. [Maxpool Backward](https://stackoverflow.com/questions/61954727/max-pooling-backpropagation-using-numpy?fbclid=IwAR2PkO13F1_Jy99n5fysZD_dvHvqYQTPqno8Z-CLVt2-P664zjU1omJxMsQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolingLayer(baseModel):\n",
    "    def __init__(self, pool_size, stride):\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        batch_size, channel, height, width = x.shape\n",
    "        output_height = (height - self.pool_size) // self.stride + 1\n",
    "        output_width = (width - self.pool_size) // self.stride + 1\n",
    "        self.output = np.zeros((batch_size, channel, output_height, output_width))\n",
    "        \n",
    "        # maxpooling without loop\n",
    "        window_arr = np.lib.stride_tricks.as_strided(x, \n",
    "            shape=(batch_size, channel, output_height, output_width, self.pool_size, self.pool_size), \n",
    "            strides=(x.strides[0], x.strides[1], x.strides[2] * self.stride, x.strides[3] * self.stride, x.strides[2], x.strides[3]))\n",
    "        self.output = np.max(window_arr, axis=(4, 5))\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        x = self.x\n",
    "        batch_size, channel, height, width = x.shape\n",
    "        out_batch, out_channel, out_height, out_width = output.shape\n",
    "\n",
    "        dx = np.zeros(shape=x.shape)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            for j in range(channel):\n",
    "                for k in range(out_height):\n",
    "                    for l in range(out_width):\n",
    "                        # get the index in the region i,j where the value is the maximum\n",
    "                        i_t, j_t = np.where(np.max(x[i, j, k * self.stride : k * self.stride + self.pool_size, l * self.stride : l * self.stride + self.pool_size]) == x[i, j, k * self.stride : k * self.stride + self.pool_size, l * self.stride : l * self.stride + self.pool_size])\n",
    "                        i_t, j_t = i_t[0], j_t[0]\n",
    "                        # print(i_t, j_t)\n",
    "                        # only the position of the maximum element in the region i,j gets the incoming gradient, the other gradients are zero\n",
    "                        dx[i, j, k * self.stride : k * self.stride + self.pool_size, l * self.stride : l * self.stride + self.pool_size][i_t, j_t] = output[i, j, k, l]\n",
    "        return dx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 2, 2)\n",
      "output--------\n",
      "[[[[0. 0.]\n",
      "   [0. 0.]]]]\n",
      "\n",
      "(1, 1, 3, 3)\n",
      "output--------\n",
      "[[[[0. 0. 0.]\n",
      "   [0. 0. 0.]\n",
      "   [0. 0. 0.]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxpool_layer = MaxPoolingLayer(2, 1)   \n",
    "output = maxpool_layer.forward(output)\n",
    "\n",
    "print(output.shape)\n",
    "print(f'output--------\\n{output}\\n')\n",
    "\n",
    "output_rev = maxpool_layer.backward(output, 0.1)\n",
    "print(output_rev.shape)\n",
    "print(f'output--------\\n{output_rev}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatteningLayer(baseModel):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        batch_size, channel, height, width = x.shape\n",
    "        self.output = x.reshape((batch_size, channel * height * width))\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        self.output = output\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        dx = self.output.reshape(self.x.shape)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "output--------\n",
      "[[0. 0. 0. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flat_layer = FlatteningLayer()\n",
    "output = flat_layer.forward(output)\n",
    "print(output.shape)\n",
    "print(f'output--------\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-connected layer: a dense layer. There will be one paramete:\n",
    "1. Output dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer(baseModel):\n",
    "    def __init__(self, output_channel):\n",
    "        self.output_channel = output_channel\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.x = None\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "\n",
    "        # print(f'fully connected layer input: {self.x}' )\n",
    "\n",
    "        if self.weights is None:\n",
    "            self.weights = np.random.randn(self.x.shape[1], self.output_channel) * np.sqrt(2 / self.x.shape[1])\n",
    "            self.bias = np.zeros(self.output_channel)\n",
    "            \n",
    "        self.output = np.dot(self.x, self.weights) + self.bias\n",
    "\n",
    "        # print(f'fully connected layer output: {self.output}' )\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        self.output = output\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        dw = np.dot(self.x.T, self.output)\n",
    "        db = np.sum(self.output, axis=0)\n",
    "        dx = np.dot(self.output, self.weights.T)\n",
    "\n",
    "        self.weights -= self.learning_rate * dw \n",
    "        self.bias -= self.learning_rate * db\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n",
      "output--------\n",
      "[[ 0.09181723  0.06503614  0.14569089  0.02371608  0.11542386  0.06832405\n",
      "  -0.0102092  -0.11068653 -0.02982713  0.1893987 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fullConn_layer = FullyConnectedLayer(10)\n",
    "output = fullConn_layer.forward(output)\n",
    "print(output.shape)\n",
    "print(f'output--------\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax: it will convert final layer projections to normalized probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLayer(baseModel):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "\n",
    "        # print(f'softmax layer input: {self.x}' )\n",
    "\n",
    "\n",
    "        # normalize input\n",
    "        x -= np.max(x, axis=1, keepdims=True)\n",
    "        x_exp = np.exp(x)\n",
    "        sum_exp = np.sum(x_exp, axis=1, keepdims=True)\n",
    "        sum_exp[ sum_exp == 0] = 1\n",
    "        self.output = x_exp / sum_exp\n",
    "\n",
    "        # print(f'softmax layer output: {self.output}' )\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output, learning_rate):\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n",
      "output--------\n",
      "[[0.1033975  0.10066516 0.10912069 0.09659043 0.10586741 0.10099668\n",
      "  0.09336853 0.08444303 0.09155469 0.11399588]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax_layer = SoftmaxLayer()\n",
    "output = softmax_layer.forward(output)\n",
    "print(output.shape)\n",
    "print(f'output--------\\n{output}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    model = []\n",
    "    \n",
    "    model.append(ConvolutionLayer(6, 5, 1, 0))\n",
    "    model.append(ReLULayer())\n",
    "    model.append(MaxPoolingLayer(2, 2))\n",
    "    model.append(ConvolutionLayer(16, 5, 1, 0))\n",
    "    model.append(ReLULayer())\n",
    "    model.append(MaxPoolingLayer(2, 2))\n",
    "    model.append(FlatteningLayer())\n",
    "    model.append(FullyConnectedLayer(10))\n",
    "    model.append(SoftmaxLayer())\n",
    "    print('model created: ', model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get images\n",
    "def getImages(path):\n",
    "    images = []\n",
    "    count = 0\n",
    "    path_split = path.split('.')\n",
    "    new_path = path_split[0]\n",
    "    df = pd.read_csv(path)\n",
    "    files = df['filename']\n",
    "    for file in files:\n",
    "        if count == 1000:\n",
    "            break\n",
    "        img = cv2.imread(os.path.join(new_path, file))\n",
    "        img = cv2.resize(img, (28, 28))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = (255-img.transpose(2, 0, 1))/255\n",
    "        images.append(img)\n",
    "        count += 1\n",
    "\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "def getLabels(path):\n",
    "    labels = []\n",
    "    # using panda\n",
    "    count = 1000\n",
    "    df = pd.read_csv(path)\n",
    "    labels = df['digit'][:count]\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "def train(model, X_train, X_test, Y_train, Y_test, learning_rate, epochs):\n",
    "    batch_size = 32\n",
    "    for epoch in range(epochs):\n",
    "        print(f'epoch: {epoch+1}/{epochs}')\n",
    "        num_batches = X_train.shape[0] // batch_size\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        for i in tqdm(range(num_batches)):\n",
    "            # forward\n",
    "            x_batch = X_train[i*batch_size: (i+1)*batch_size]\n",
    "            y_output = Y_train[i*batch_size: (i+1)*batch_size]\n",
    "\n",
    "            x_output = x_batch\n",
    "            for layer in model:\n",
    "                x_output = layer.forward(x_output)\n",
    "            \n",
    "            #loss\n",
    "            loss += log_loss(y_output, x_output)\n",
    "            accuracy += accuracy_score(np.argmax(y_output, axis=1), np.argmax(x_output, axis=1))\n",
    "\n",
    "            dL = np.copy(x_output)\n",
    "            dL -= y_output\n",
    "            dL /= batch_size\n",
    "            # backward\n",
    "            for layer in reversed(model):\n",
    "                dL = layer.backward(dL, learning_rate)\n",
    "        \n",
    "        # test\n",
    "        val_loss = 0\n",
    "        \n",
    "        x_out = X_test\n",
    "        for layer in model:\n",
    "            x_out = layer.forward(x_out)\n",
    "\n",
    "        # print(f'loss: {loss/num_batches}, val_loss: {val_loss}')\n",
    "        val_loss = log_loss(Y_test, x_out)\n",
    "        val_accuracy = accuracy_score(np.argmax(Y_test, axis=1), np.argmax(x_out, axis=1))\n",
    "        val_F1 = f1_score(np.argmax(Y_test, axis=1), np.argmax(x_out, axis=1), average='macro')\n",
    "        print(f'loss: {loss/num_batches}, val_loss: {val_loss}')\n",
    "        print(f'accuracy: {accuracy/num_batches}, val_accuracy: {val_accuracy}')\n",
    "        print(f'val_F1: {val_F1}')\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3, 28, 28)\n",
      "(1000, 10)\n",
      "[0 0 0 1 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = getImages('data/training-a.csv')\n",
    "labels = getLabels('data/training-a.csv')\n",
    "# # images.append(image)\n",
    "# # labels.append(label)\n",
    "# image += getImages('data/training-b')\n",
    "# label += getLabels('data/training-b.csv')\n",
    "# # images.append(image)\n",
    "# # labels.append(label)\n",
    "\n",
    "\n",
    "# one hot encode\n",
    "labels = np.eye(10)[labels].astype(int)\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "# view an image\n",
    "plt.imshow(images[1].transpose(1, 2, 0))\n",
    "print(labels[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model created:  [<__main__.ConvolutionLayer object at 0x7fe9e43d9dc0>, <__main__.ReLULayer object at 0x7fe9e43d95e0>, <__main__.MaxPoolingLayer object at 0x7fe9e43d9f40>, <__main__.ConvolutionLayer object at 0x7fe9e43d9610>, <__main__.ReLULayer object at 0x7fe9e43d96d0>, <__main__.MaxPoolingLayer object at 0x7fe9e43d9f70>, <__main__.FlatteningLayer object at 0x7fe9e43d9c10>, <__main__.FullyConnectedLayer object at 0x7fe9e43d9a90>, <__main__.SoftmaxLayer object at 0x7fe9e43d94f0>]\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 3, 28, 28)\n",
      "(200, 3, 28, 28)\n",
      "(800, 10)\n",
      "(200, 10)\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:13<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.3660711740043108, val_loss: 2.323368277151544\n",
      "accuracy: 0.10875, val_accuracy: 0.09\n",
      "val_F1: 0.04290414547696101\n",
      "epoch: 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.3185451613580397, val_loss: 2.2987165761515103\n",
      "accuracy: 0.095, val_accuracy: 0.1\n",
      "val_F1: 0.06851973404049863\n",
      "epoch: 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.3005832662592325, val_loss: 2.285759207654824\n",
      "accuracy: 0.10625, val_accuracy: 0.11\n",
      "val_F1: 0.0788634284371699\n",
      "epoch: 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2882623648328178, val_loss: 2.27641005571535\n",
      "accuracy: 0.12125, val_accuracy: 0.145\n",
      "val_F1: 0.11269230769230769\n",
      "epoch: 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2782869726510517, val_loss: 2.2687038877348384\n",
      "accuracy: 0.135, val_accuracy: 0.16\n",
      "val_F1: 0.12555096406148297\n",
      "epoch: 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.269223028030822, val_loss: 2.2617990865037\n",
      "accuracy: 0.15375, val_accuracy: 0.165\n",
      "val_F1: 0.12952898503050478\n",
      "epoch: 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.260530905705243, val_loss: 2.2547761525101873\n",
      "accuracy: 0.1775, val_accuracy: 0.19\n",
      "val_F1: 0.14839634099253735\n",
      "epoch: 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.251655610168555, val_loss: 2.2470460902134395\n",
      "accuracy: 0.195, val_accuracy: 0.205\n",
      "val_F1: 0.15895468223459835\n",
      "epoch: 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.242097321125472, val_loss: 2.2382693616249894\n",
      "accuracy: 0.21125, val_accuracy: 0.23\n",
      "val_F1: 0.17920388411929894\n",
      "epoch: 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.231801866201265, val_loss: 2.2287016688052472\n",
      "accuracy: 0.22625, val_accuracy: 0.225\n",
      "val_F1: 0.17446293014289227\n",
      "epoch: 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:15<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.220439411578354, val_loss: 2.2180293340887234\n",
      "accuracy: 0.24, val_accuracy: 0.26\n",
      "val_F1: 0.2158326265977335\n",
      "epoch: 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:15<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.2076755674391846, val_loss: 2.206455460208218\n",
      "accuracy: 0.25125, val_accuracy: 0.26\n",
      "val_F1: 0.21258432532468685\n",
      "epoch: 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.1930719373166414, val_loss: 2.1936676252268548\n",
      "accuracy: 0.255, val_accuracy: 0.27\n",
      "val_F1: 0.22278586859788296\n",
      "epoch: 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.1766765943445368, val_loss: 2.179512509572054\n",
      "accuracy: 0.2575, val_accuracy: 0.27\n",
      "val_F1: 0.222796066252588\n",
      "epoch: 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:16<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.159011315692948, val_loss: 2.1640247301191886\n",
      "accuracy: 0.2675, val_accuracy: 0.28\n",
      "val_F1: 0.23691393049697407\n",
      "epoch: 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.139888997380875, val_loss: 2.1475517775898734\n",
      "accuracy: 0.2825, val_accuracy: 0.29\n",
      "val_F1: 0.24693713263480704\n",
      "epoch: 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.118928310750239, val_loss: 2.129397226139795\n",
      "accuracy: 0.2925, val_accuracy: 0.3\n",
      "val_F1: 0.26154612738086247\n",
      "epoch: 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:15<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.0960238693739455, val_loss: 2.11018371502504\n",
      "accuracy: 0.30125, val_accuracy: 0.305\n",
      "val_F1: 0.2674860988814477\n",
      "epoch: 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.0709458680142805, val_loss: 2.088794378767815\n",
      "accuracy: 0.3175, val_accuracy: 0.315\n",
      "val_F1: 0.27930607117913614\n",
      "epoch: 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.0440972308123824, val_loss: 2.0653812683130113\n",
      "accuracy: 0.3275, val_accuracy: 0.325\n",
      "val_F1: 0.2896924873085863\n",
      "epoch: 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.015401199847236, val_loss: 2.0406958640611803\n",
      "accuracy: 0.33625, val_accuracy: 0.34\n",
      "val_F1: 0.30333774469258334\n",
      "epoch: 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.9847857486858793, val_loss: 2.0143137263175817\n",
      "accuracy: 0.35125, val_accuracy: 0.345\n",
      "val_F1: 0.30612899516292574\n",
      "epoch: 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.9523210117478484, val_loss: 1.9860741605890195\n",
      "accuracy: 0.35875, val_accuracy: 0.355\n",
      "val_F1: 0.3087231450595029\n",
      "epoch: 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.9180659389696344, val_loss: 1.9558070194121637\n",
      "accuracy: 0.37125, val_accuracy: 0.36\n",
      "val_F1: 0.3108515859331688\n",
      "epoch: 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.8817344110052818, val_loss: 1.9232567717982396\n",
      "accuracy: 0.39, val_accuracy: 0.37\n",
      "val_F1: 0.3277540462677596\n",
      "epoch: 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.8437170022692602, val_loss: 1.8889498184170446\n",
      "accuracy: 0.39375, val_accuracy: 0.38\n",
      "val_F1: 0.33736603836830154\n",
      "epoch: 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.8041134592492312, val_loss: 1.8529777243171839\n",
      "accuracy: 0.40875, val_accuracy: 0.39\n",
      "val_F1: 0.3480261643694277\n",
      "epoch: 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:15<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.7631932293442185, val_loss: 1.8150253924588833\n",
      "accuracy: 0.41875, val_accuracy: 0.395\n",
      "val_F1: 0.3499130934425052\n",
      "epoch: 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.7215174714795143, val_loss: 1.776934543343101\n",
      "accuracy: 0.435, val_accuracy: 0.395\n",
      "val_F1: 0.3494079610612424\n",
      "epoch: 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.680025297567052, val_loss: 1.7387333844907722\n",
      "accuracy: 0.44125, val_accuracy: 0.41\n",
      "val_F1: 0.36106897025185936\n"
     ]
    }
   ],
   "source": [
    "train(model, X_train, X_test, Y_train, Y_test, 0.01, 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
